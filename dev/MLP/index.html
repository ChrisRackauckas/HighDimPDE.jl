<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>The MLP algorithm ¬∑ HighDimPDE.jl</title><meta name="title" content="The MLP algorithm ¬∑ HighDimPDE.jl"/><meta property="og:title" content="The MLP algorithm ¬∑ HighDimPDE.jl"/><meta property="twitter:title" content="The MLP algorithm ¬∑ HighDimPDE.jl"/><meta name="description" content="Documentation for HighDimPDE.jl."/><meta property="og:description" content="Documentation for HighDimPDE.jl."/><meta property="twitter:description" content="Documentation for HighDimPDE.jl."/><meta property="og:url" content="https://docs.sciml.ai/HighDimPDE/stable/MLP/"/><meta property="twitter:url" content="https://docs.sciml.ai/HighDimPDE/stable/MLP/"/><link rel="canonical" href="https://docs.sciml.ai/HighDimPDE/stable/MLP/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="HighDimPDE.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">HighDimPDE.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting_started/">Getting started</a></li><li><a class="tocitem" href="../problems/">Problems</a></li><li><span class="tocitem">Solver Algorithms</span><ul><li class="is-active"><a class="tocitem" href>The <code>MLP</code> algorithm</a><ul class="internal"><li><a class="tocitem" href="#The-general-idea"><span>The general idea üí°</span></a></li><li><a class="tocitem" href="#Non-local-PDEs"><span>Non-local PDEs</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../DeepSplitting/">The <code>DeepSplitting</code> algorithm</a></li><li><a class="tocitem" href="../DeepBSDE/">The <code>DeepBSDE</code> algorithm</a></li><li><a class="tocitem" href="../NNStopping/">The <code>NNStopping</code> algorithm</a></li><li><a class="tocitem" href="../NNKolmogorov/">The <code>NNKolmogorov</code> algorithm</a></li><li><a class="tocitem" href="../NNParamKolmogorov/">The <code>NNParamKolmogorov</code> algorithm</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/deepsplitting/"><code>DeepSplitting</code></a></li><li><a class="tocitem" href="../tutorials/deepbsde/"><code>DeepBSDE</code></a></li><li><a class="tocitem" href="../tutorials/mlp/"><code>MLP</code></a></li><li><a class="tocitem" href="../tutorials/nnstopping/"><code>NNStopping</code></a></li><li><a class="tocitem" href="../tutorials/nnkolmogorov/"><code>NNKolmogorov</code></a></li><li><a class="tocitem" href="../tutorials/nnparamkolmogorov/"><code>NNParamKolmogorov</code></a></li></ul></li><li><a class="tocitem" href="../Feynman_Kac/">Feynman Kac formula</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solver Algorithms</a></li><li class="is-active"><a href>The <code>MLP</code> algorithm</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>The <code>MLP</code> algorithm</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/HighDimPDE.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ÔÇõ</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/HighDimPDE.jl/blob/main/docs/src/MLP.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ÔÅÑ</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="mlp"><a class="docs-heading-anchor" href="#mlp">The <code>MLP</code> algorithm</a><a id="mlp-1"></a><a class="docs-heading-anchor-permalink" href="#mlp" title="Permalink"></a></h1><h3 id="Problems-Supported:"><a class="docs-heading-anchor" href="#Problems-Supported:">Problems Supported:</a><a id="Problems-Supported:-1"></a><a class="docs-heading-anchor-permalink" href="#Problems-Supported:" title="Permalink"></a></h3><ol><li><a href="../problems/#HighDimPDE.PIDEProblem"><code>PIDEProblem</code></a></li><li><a href="../problems/#HighDimPDE.ParabolicPDEProblem"><code>ParabolicPDEProblem</code></a></li></ol><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="HighDimPDE.MLP" href="#HighDimPDE.MLP"><code>HighDimPDE.MLP</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><p>Multi level Picard algorithm.</p><p><strong>Arguments</strong></p><ul><li><code>L</code>: number of Picard iterations (Level),</li><li><code>M</code>: number of Monte Carlo integrations (at each level <code>l</code>, <code>M^(L-l)</code>integrations),</li><li><code>K</code>: number of Monte Carlo integrations for the non-local term</li><li><code>mc_sample::MCSampling</code> : sampling method for Monte Carlo integrations of the non local term.</li></ul><p>Can be <code>UniformSampling(a,b)</code>, <code>NormalSampling(œÉ_sampling)</code>, or <code>NoSampling</code> (by default).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/HighDimPDE.jl/blob/4b78e9d0df37cc150edfddc515235f34d26ffed0/src/MLP.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="CommonSolve.solve-Tuple{Union{PIDEProblem, ParabolicPDEProblem}, MLP}" href="#CommonSolve.solve-Tuple{Union{PIDEProblem, ParabolicPDEProblem}, MLP}"><code>CommonSolve.solve</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">solve(
    prob::Union{PIDEProblem, ParabolicPDEProblem},
    alg::MLP;
    multithreading,
    verbose
) -&gt; PIDESolution{_A, _B, Nothing, _C, Nothing, Nothing} where {_A, _B, _C}
</code></pre><p>Returns a <code>PIDESolution</code> object.</p><p><strong>Arguments</strong></p><ul><li><code>multithreading</code> : if <code>true</code>, distributes the job over all the threads available.</li><li><code>verbose</code>: print information over the iterations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/HighDimPDE.jl/blob/4b78e9d0df37cc150edfddc515235f34d26ffed0/src/MLP.jl#L23">source</a></section></article><p>The <code>MLP</code>, for Multi-Level Picard iterations, reformulates the PDE problem as a fixed point equation through the Feynman Kac formula. </p><ul><li><p>It relies on <a href="https://en.wikipedia.org/wiki/Picard‚ÄìLindel√∂f_theorem">Picard iterations</a> to find the fixed point, </p></li><li><p>reducing the complexity of the numerical approximation of the time integral through a <a href="https://en.wikipedia.org/wiki/Multilevel_Monte_Carlo_method">multilevel Monte Carlo</a> approach.</p></li></ul><p>The <code>MLP</code> algorithm overcomes the curse of dimensionality, with a computational complexity that grows polynomially in the number of dimension (see <a href="https://arxiv.org/abs/1807.01212v3">M. Hutzenthaler et al. 2020</a>).</p><div class="admonition is-warning"><header class="admonition-header">`MLP` can only approximate the solution on a single point</header><div class="admonition-body"><p><code>MLP</code> only works for <code>PIDEProblem</code> with <code>x0_sample = NoSampling()</code>. If you want to solve over an entire domain, you definitely want to check the <code>DeepSplitting</code> algorithm.</p></div></div><h2 id="The-general-idea"><a class="docs-heading-anchor" href="#The-general-idea">The general idea üí°</a><a id="The-general-idea-1"></a><a class="docs-heading-anchor-permalink" href="#The-general-idea" title="Permalink"></a></h2><p>Consider the PDE</p><p class="math-container">\[\partial_t u(t,x) = \mu(t, x) \nabla_x u(t,x) + \frac{1}{2} \sigma^2(t, x) \Delta_x u(t,x) + f(x, u(t,x)) \tag{1}\]</p><p>with initial conditions <span>$u(0, x) = g(x)$</span>, where <span>$u \colon \R^d \to \R$</span>. </p><h3 id="Picard-Iterations"><a class="docs-heading-anchor" href="#Picard-Iterations">Picard Iterations</a><a id="Picard-Iterations-1"></a><a class="docs-heading-anchor-permalink" href="#Picard-Iterations" title="Permalink"></a></h3><p>The <code>MLP</code> algorithm observes that the <a href="../Feynman_Kac/#feynmankac">Feynman Kac formula</a> can be viewed as a fixed point equation, i.e. <span>$u = \phi(u)$</span>. Introducing a sequence <span>$(u_k)$</span> defined as <span>$u_0 = g$</span> and </p><p class="math-container">\[u_{l+1} = \phi(u_l),\]</p><p>the <a href="https://en.wikipedia.org/wiki/Banach_fixed-point_theorem">Banach fixed-point theorem</a> ensures that the sequence converges to the true solution <span>$u$</span>. Such a technique is known as <a href="https://en.wikipedia.org/wiki/Picard‚ÄìLindel√∂f_theorem">Picard iterations</a>.</p><p>The time integral term is evaluated by a <a href="https://en.wikipedia.org/wiki/Monte_Carlo_integration">Monte-Carlo integration</a></p><p class="math-container">\[u_L  = \frac{1}{M}\sum_i^M \left[ f(X^{x,(i)}_{t - s_{(l, i)}}, u_{L-1}(T-s_i, X^{x,( i)}_{t - s_{(l, i)}})) + u(0, X^{x,(i)}_{t - s_{(l, i)}}) \right].\]</p><p>But the MLP uses an extra trick to lower the computational cost of the iteration. </p><h3 id="Telescope-sum"><a class="docs-heading-anchor" href="#Telescope-sum">Telescope sum</a><a id="Telescope-sum-1"></a><a class="docs-heading-anchor-permalink" href="#Telescope-sum" title="Permalink"></a></h3><p>The <code>MLP</code> algorithm uses a telescope sum </p><p class="math-container">\[\begin{aligned}
u_L = \phi(u_{L-1}) &amp;= [\phi(u_{L-1}) - \phi(u_{L-2})] + [\phi(u_{L-2}) - \phi(u_{L-3})] + \dots \\
&amp;= \sum_{l=1}^{L-1} [\phi(u_{l-1}) - \phi(u_{l-2})]
\end{aligned}\]</p><p>As <span>$l$</span> grows, the term <span>$[\phi(u_{l-1}) - \phi(u_{l-2})]$</span> becomes smaller, and thus demands more calculations. The <code>MLP</code> algorithm uses this fact by evaluating the integral term at level <span>$l$</span> with <span>$M^{L-l}$</span> samples.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><ul><li><code>L</code> corresponds to the level of the approximation, i.e. <span>$u \approx u_L$</span></li><li><code>M</code> characterizes the number of samples for the Monte Carlo approximation of the time integral</li></ul></div></div><p>Overall, <code>MLP</code> can be summarized by the following formula</p><p class="math-container">\[\begin{aligned}
u_L &amp;= \sum_{l=1}^{L-1} \frac{1}{M^{L-l}}\sum_i^{M^{L-l}} \left[ f(X^{x,(l, i)}_{t - s_{(l, i)}}, u(T-s_{(l, i)}, X^{x,(l, i)}_{t - s_{(l, i)}})) + \mathbf{1}_\N(l) f(X^{x,(l, i)}_{t - s_{(l, i)}}, u(T-s_{(l, i)}, X^{x,(l, i)}_{t - s_{(l, i)}}))\right]
\\
&amp;\qquad + \frac{1}{M^{L}}\sum_i^{M^{L}} u(0, X^{x,(l, i)}_t)\\
\end{aligned}\]</p><p>Note that the superscripts <span>$(l, i)$</span> indicate the independence of the random variables <span>$X$</span> across levels.</p><h2 id="Non-local-PDEs"><a class="docs-heading-anchor" href="#Non-local-PDEs">Non-local PDEs</a><a id="Non-local-PDEs-1"></a><a class="docs-heading-anchor-permalink" href="#Non-local-PDEs" title="Permalink"></a></h2><p><code>MLP</code> can solve for non-local reaction diffusion equations of the type</p><p class="math-container">\[\partial_t u = \mu(t, x) \nabla_x u(t, x) + \frac{1}{2} \sigma^2(t, x) \Delta u(t, x) + \int_{\Omega}f(x, y, u(t,x), u(t,y))dy\]</p><p>The non-localness is handled by a Monte Carlo integration.</p><p class="math-container">\[\begin{aligned}
u_L &amp;= \sum_{l=1}^{L-1} \frac{1}{M^{L-l}}\sum_{i=1}^{M^{L-l}} \frac{1}{K}\sum_{j=1}^{K}  \bigg[ f(X^{x,(l, i)}_{t - s_{(l, i)}}, Z^{(l,j)}, u(T-s_{(l, i)}, X^{x,(l, i)}_{t - s_{(l, i)}}), u(T-s_{l,i}, Z^{(l,j)})) + \\
&amp;\qquad 
\mathbf{1}_\N(l) f(X^{x,(l, i)}_{t - s_{(l, i)}}, u(T-s_{(l, i)}, X^{x,(l, i)}_{t - s_{(l, i)}}))\bigg] + \frac{1}{M^{L}}\sum_i^{M^{L}} u(0, X^{x,(l, i)}_t)\\
\end{aligned}\]</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>In practice, if you have a non-local model, you need to provide the sampling method and the number <span>$K$</span> of MC integration through the keywords <code>mc_sample</code> and <code>K</code>. </p><ul><li><code>K</code> characterizes the number of samples for the Monte Carlo approximation of the last term.</li><li><code>mc_sample</code> characterizes the distribution of the <code>Z</code> variables</li></ul></div></div><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ul><li>Boussange, V., Becker, S., Jentzen, A., Kuckuck, B., Pellissier, L., Deep learning approximations for non-local nonlinear PDEs with Neumann boundary conditions. <a href="https://arxiv.org/abs/2205.03672">arXiv</a> (2022)</li><li>Becker, S., Braunwarth, R., Hutzenthaler, M., Jentzen, A., von Wurstemberger, P., Numerical simulations for full history recursive multilevel Picard approximations for systems of high-dimensional partial differential equations. <a href="https://arxiv.org/abs/2005.10206">arXiv</a> (2020)</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../problems/">¬´ Problems</a><a class="docs-footer-nextpage" href="../DeepSplitting/">The <code>DeepSplitting</code> algorithm ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.0 on <span class="colophon-date" title="Friday 19 April 2024 01:24">Friday 19 April 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
